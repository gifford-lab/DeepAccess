{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import ensemble_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = [line.split('\\n')[1] for line in open('data/test.fa').read().split('>')[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqhot = ensemble_utils.fa_to_onehot('data/test.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmer_range=range(8,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant sequences at k = 8 dict_keys(['ATTATGTA', 'TTATGTAC', 'TATGTACA', 'ATGTACAC', 'CATACATT', 'ATACATTT', 'TACATTTA', 'ACATTTAC', 'CATTTACA', 'ATATGCAT', 'TATGCATG', 'ATGCATGC', 'TGCATGCA', 'TACACATA', 'ACACATAT', 'CACATATG'])\n",
      "Significant sequences at k = 9 dict_keys(['ATTATGTAC', 'TTATGTACA', 'TATGTACAC', 'CATACATTT', 'ATACATTTA', 'TACATTTAC', 'ACATTTACA', 'ATATGCATG', 'TATGCATGC', 'ATGCATGCA', 'TATGAACAT', 'TACACATAT', 'TTCACATAT'])\n",
      "Significant sequences at k = 10 dict_keys(['ATTATGTACA', 'TTATGTACAC', 'TATGTACACA', 'CCATACATTT', 'CATACATTTA', 'ATACATTTAC', 'TACATTTACA', 'TATATGCATG', 'ATATGCATGC', 'TATGCATGCA', 'ATGCATGCAC', 'ATATGAACAT', 'GTACACATAT', 'TACACATATT', 'TATTCACATA', 'ATTCACATAT', 'TTCACATATG'])\n",
      "Significant sequences at k = 11 dict_keys(['ATTATGTACAC', 'TTATGTACACA', 'CCCATACATTT', 'CCATACATTTA', 'CATACATTTAC', 'ATACATTTACA', 'TACATTTACAG', 'TATATGCATGC', 'ATATGCATGCA', 'TATGAACATTT', 'TACACATATTT', 'TATTCACATAT', 'ATTCACATATG'])\n"
     ]
    }
   ],
   "source": [
    "#Differentially Salient class 0 vs class 1\n",
    "with open('example/test_saliency_0vs1.pkl','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    mat = seqhot*data\n",
    "    for kmer_size in kmer_range:\n",
    "        windows = np.array([np.mean(mat[i,j:(j+kmer_size),:]) for i in range(len(seqs)) for j in range(len(seqs[0])-kmer_size+1)])\n",
    "        mu_window = np.mean(windows)\n",
    "        sigma_window = np.std(windows)\n",
    "        significant_seqs =  {}\n",
    "        significant_pvals = {}\n",
    "        nhypothesis = windows.shape[0]\n",
    "        for i in range(len(seqs)):\n",
    "            for j in range(len(seqs[0])-kmer_size+1):\n",
    "                score=np.mean(mat[i,j:(j+kmer_size)])\n",
    "                pval = norm.sf(score,\n",
    "                               loc=mu_window,scale=sigma_window)\n",
    "                if pval < 0.05/(nhypothesis):\n",
    "                    try:\n",
    "                        key = significant_seqs[seqs[i][j:j+kmer_size].upper()]\n",
    "                        old_pval = significant_pvals[seqs[i][j:j+kmer_size].upper()]\n",
    "                        pval = min(pval,old_pval)\n",
    "                    except KeyError:\n",
    "                        significant_seqs[seqs[i][j:j+kmer_size].upper()] = np.zeros((kmer_size,4))\n",
    "                    significant_pvals[seqs[i][j:j+kmer_size].upper()] = pval\n",
    "                    significant_seqs[seqs[i][j:j+kmer_size].upper()] += mat[i,j:j+kmer_size,:]\n",
    "        print('Significant sequences at k =',kmer_size,significant_seqs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant sequences at k = 8 dict_keys(['GTGTGTGC', 'TGTGTGCA', 'GTGTGCAT', 'TGTGCATG', 'GTGCATGC', 'AATTTGCA', 'ATTTGCAT', 'ATTATGTA', 'TTATGTAC', 'TATGTACA', 'ATGTACAC', 'TGTACACA', 'ATACATTT', 'TACATTTA', 'ATATATAC', 'TATATGCA', 'ATATGCAT', 'TATGCATG', 'ATGCATGC', 'TGCATGCA', 'GCATGCAC', 'TAAATGTA', 'ATGTAAAT', 'GTACTTAC', 'TACTTACA', 'ACTTACAT', 'TTACATAT', 'TACATATG', 'GTACACAT', 'TACACATA', 'ACACATAT', 'ACATATTT', 'ATTCACAT', 'TTCACATA', 'TATTCACA', 'TCACATAT', 'CACATATG'])\n",
      "Significant sequences at k = 9 dict_keys(['GTGTGTGCA', 'TGTGTGCAT', 'GTGTGCATG', 'TGTGCATGC', 'ATTATGTAC', 'TTATGTACA', 'TATGTACAC', 'ATGTACACA', 'CATACATTT', 'ATACATTTA', 'TACATTTAC', 'ATATATACA', 'TATATGCAT', 'ATATGCATG', 'TATGCATGC', 'ATGCATGCA', 'TGCATGCAC', 'GCATGCACA', 'AAATGTAAA', 'GTACTTACA', 'TACTTACAT', 'ACTTACATA', 'TGTACACAT', 'GTACACATA', 'TACACATAT', 'ACACATATT', 'CACATATTT', 'ATTCACATA', 'TTCACATAA', 'ATTTATTCA', 'TATTCACAT', 'TTCACATAT', 'TCACATATG', 'ACATATGAA'])\n",
      "Significant sequences at k = 10 dict_keys(['GTGTGTGCAT', 'TGTGTGCATG', 'GTGTGCATGC', 'ATTATGTACA', 'TTATGTACAC', 'TATGTACACA', 'ATGTACACAC', 'CATACATTTA', 'ATACATTTAC', 'TACATTTACA', 'TTATATGCAT', 'TATATGCATG', 'ATATGCATGC', 'TATGCATGCA', 'ATGCATGCAC', 'TGCATGCACA', 'TAAATGTAAA', 'AAATGTAAAT', 'GTACTTACAT', 'TACTTACATA', 'ACTTACATAT', 'TGTACACATA', 'GTACACATAT', 'TACACATATT', 'ACACATATTT', 'ATTTATTCAC', 'TTATTCACAT', 'TATTCACATA', 'ATTCACATAT', 'TTCACATATG', 'CACATATGAA'])\n",
      "Significant sequences at k = 11 dict_keys(['GTGTGTGCATG', 'TGTGTGCATGC', 'ATTATGTACAC', 'TTATGTACACA', 'TATGTACACAC', 'ATGTACACACA', 'ATACATTTACA', 'TTATATGCATG', 'TATATGCATGC', 'ATATGCATGCA', 'TATGCATGCAC', 'ATGCATGCACA', 'TGCATGCACAC', 'TAAATGTAAAT', 'AAATGTAAATG', 'GTACTTACATA', 'TACTTACATAT', 'ACTTACATATG', 'TGTACACATAT', 'GTACACATATT', 'TACACATATTT', 'ATTTATTCACA', 'TTATTCACATA', 'TATTCACATAT', 'ATTCACATATG'])\n"
     ]
    }
   ],
   "source": [
    "#Salient class 0 \n",
    "with open('example/test_saliency_0vsNone.pkl','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    mat = seqhot*data\n",
    "    \n",
    "    for kmer_size in kmer_range:\n",
    "        windows = np.array([np.mean(mat[i,j:(j+kmer_size),:]) for i in range(len(seqs)) for j in range(len(seqs[0])-kmer_size+1)])\n",
    "        mu_window = np.mean(windows)\n",
    "        sigma_window = np.std(windows)\n",
    "        significant_seqs =  {}\n",
    "        significant_pvals = {}\n",
    "        nhypothesis = windows.shape[0]\n",
    "        for i in range(len(seqs)):\n",
    "            for j in range(len(seqs[0])-kmer_size+1):\n",
    "                score=np.mean(mat[i,j:(j+kmer_size)])\n",
    "                pval = norm.sf(score,\n",
    "                               loc=mu_window,scale=sigma_window)\n",
    "                if pval < 0.05/(nhypothesis):\n",
    "                    try:\n",
    "                        key = significant_seqs[seqs[i][j:j+kmer_size].upper()]\n",
    "                        old_pval = significant_pvals[seqs[i][j:j+kmer_size].upper()]\n",
    "                        pval = min(pval,old_pval)\n",
    "                    except KeyError:\n",
    "                        significant_seqs[seqs[i][j:j+kmer_size].upper()] = np.zeros((kmer_size,4))\n",
    "                    significant_pvals[seqs[i][j:j+kmer_size].upper()] = pval\n",
    "                    significant_seqs[seqs[i][j:j+kmer_size].upper()] += mat[i,j:j+kmer_size,:]\n",
    "        print('Significant sequences at k =',kmer_size,significant_seqs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant sequences at k = 8 dict_keys(['TGTCTCCT', 'GTCTCCTT', 'AAAGGGCC', 'AAGGGCCA', 'AGGGCCAG'])\n",
      "Significant sequences at k = 9 dict_keys(['TTGTCTCCT', 'TGTCTCCTT', 'GTCTCCTTT', 'TAAAGGGCC', 'AAAGGGCCA', 'AAGGGCCAG'])\n",
      "Significant sequences at k = 10 dict_keys(['CTTTGTCTCC', 'TTTGTCTCCT', 'TGTCTCCTTT', 'GTCTCCTTTT', 'TAAAGGGCCA', 'AAAGGGCCAG'])\n",
      "Significant sequences at k = 11 dict_keys(['CTTTGTCTCCT', 'TGTCTCCTTTT', 'GTCTCCTTTTT'])\n"
     ]
    }
   ],
   "source": [
    "#Differentially salient class 1 vs class 0\n",
    "with open('example/test_saliency_1vs0.pkl','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    mat = seqhot*data\n",
    "    for kmer_size in kmer_range:\n",
    "        windows = np.array([np.mean(mat[i,j:(j+kmer_size),:]) for i in range(len(seqs)) for j in range(len(seqs[0])-kmer_size+1)])\n",
    "        mu_window = np.mean(windows)\n",
    "        sigma_window = np.std(windows)\n",
    "        significant_seqs =  {}\n",
    "        significant_pvals = {}\n",
    "        nhypothesis = windows.shape[0]\n",
    "        for i in range(len(seqs)):\n",
    "            for j in range(len(seqs[0])-kmer_size+1):\n",
    "                score=np.mean(mat[i,j:(j+kmer_size)])\n",
    "                pval = norm.sf(score,\n",
    "                               loc=mu_window,scale=sigma_window)\n",
    "                if pval < 0.05/(nhypothesis):\n",
    "                    try:\n",
    "                        key = significant_seqs[seqs[i][j:j+kmer_size].upper()]\n",
    "                        old_pval = significant_pvals[seqs[i][j:j+kmer_size].upper()]\n",
    "                        pval = min(pval,old_pval)\n",
    "                    except KeyError:\n",
    "                        significant_seqs[seqs[i][j:j+kmer_size].upper()] = np.zeros((kmer_size,4))\n",
    "                    significant_pvals[seqs[i][j:j+kmer_size].upper()] = pval\n",
    "                    significant_seqs[seqs[i][j:j+kmer_size].upper()] += mat[i,j:j+kmer_size,:]\n",
    "        print('Significant sequences at k =',kmer_size,significant_seqs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant sequences at k = 8 dict_keys(['TGGCCTTT', 'GCCTTTGT', 'TCTCAAAG', 'CTCAAAGG', 'TCAAAGGA', 'CAAAGGAC', 'AAAGGACC', 'AAGGACCA', 'TGCTCTGT', 'GCTCTGTA', 'CTCTGTAG', 'TCTGTAGT', 'CCTTTTGT', 'CTTTTGTC', 'GACAATGG', 'AAAAGACT', 'AAAGACTG'])\n",
      "Significant sequences at k = 9 dict_keys(['ATGGCCTTT', 'GGCCTTTGT', 'TTCTCAAAG', 'TCTCAAAGG', 'CTCAAAGGA', 'TCAAAGGAC', 'CAAAGGACC', 'AAAGGACCA', 'AAGGACCAT', 'ATTGCTCTG', 'TTGCTCTGT', 'TGCTCTGTA', 'GCTCTGTAG', 'CTCTGTAGT', 'TCTGTAGTA', 'CCTTTTGTC', 'GGACAATGG', 'AAAGACTGT'])\n",
      "Significant sequences at k = 10 dict_keys(['TTTCTCAAAG', 'TTCTCAAAGG', 'TCTCAAAGGA', 'TCAAAGGACC', 'CAAAGGACCA', 'AAAGGACCAT', 'ATTGCTCTGT', 'TTGCTCTGTA', 'TGCTCTGTAG', 'GCTCTGTAGT', 'CTCTGTAGTA', 'TGGACAATGG', 'GTCCTTTTCT'])\n",
      "Significant sequences at k = 11 dict_keys(['CTTTCTCAAAG', 'TTTCTCAAAGG', 'TTCTCAAAGGA', 'TCTCAAAGGAC', 'TCAAAGGACCA', 'CAAAGGACCAT', 'AAAGGACCATT', 'CAATTGCTCTG', 'AATTGCTCTGT', 'ATTGCTCTGTA', 'TTGCTCTGTAG', 'TGCTCTGTAGT', 'GCTCTGTAGTA', 'TTGGACAATGG'])\n"
     ]
    }
   ],
   "source": [
    "#Salient class 1\n",
    "with open('example/test_saliency_1vsNone.pkl','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    mat = seqhot*data\n",
    "    for kmer_size in kmer_range:\n",
    "        windows = np.array([np.mean(mat[i,j:(j+kmer_size),:]) for i in range(len(seqs)) for j in range(len(seqs[0])-kmer_size+1)])\n",
    "        mu_window = np.mean(windows)\n",
    "        sigma_window = np.std(windows)\n",
    "        significant_seqs =  {}\n",
    "        significant_pvals = {}\n",
    "        nhypothesis = windows.shape[0]\n",
    "        for i in range(len(seqs)):\n",
    "            for j in range(len(seqs[0])-kmer_size+1):\n",
    "                score=np.mean(mat[i,j:(j+kmer_size)])\n",
    "                pval = norm.sf(score,\n",
    "                               loc=mu_window,scale=sigma_window)\n",
    "                if pval < 0.05/(nhypothesis):\n",
    "                    try:\n",
    "                        key = significant_seqs[seqs[i][j:j+kmer_size].upper()]\n",
    "                        old_pval = significant_pvals[seqs[i][j:j+kmer_size].upper()]\n",
    "                        pval = min(pval,old_pval)\n",
    "                    except KeyError:\n",
    "                        significant_seqs[seqs[i][j:j+kmer_size].upper()] = np.zeros((kmer_size,4))\n",
    "                    significant_pvals[seqs[i][j:j+kmer_size].upper()] = pval\n",
    "                    significant_seqs[seqs[i][j:j+kmer_size].upper()] += mat[i,j:j+kmer_size,:]\n",
    "        print('Significant sequences at k =',kmer_size,significant_seqs.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
